{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고급 추론 및 문제 해결 모델 탐색  \n",
    "\n",
    "OpenAI의 o1 시리즈 모델은 강화 학습을 통해 훈련된 대형 언어 모델로, 복잡한 추론을 수행할 수 있도록 설계되었습니다. o1 모델은 답변하기 전에 깊이 사고하며, 내부적으로 긴 사고 과정을 거친 후 응답을 생성합니다.  \n",
    "\n",
    "o1 모델은 과학적 추론에서 뛰어난 성능을 보이며, 경쟁 프로그래밍(Codeforces) 문제에서 상위 89퍼센타일을 기록하고, 미국 수학 올림피아드 예선(AIME)에서 미국 상위 500명 학생 수준의 성과를 달성했으며, 물리학, 생물학, 화학 문제를 다루는 GPQA 벤치마크에서 인간 박사급 정답률을 초과했습니다.  \n",
    "\n",
    "API에서는 두 가지 추론 모델을 사용할 수 있습니다:  \n",
    "\n",
    "- **o1**: 광범위한 일반 지식을 활용하여 어려운 문제를 추론하도록 설계된 모델  \n",
    "- **o1-mini**: 보다 빠르고 경제적인 버전의 o1 모델로, 방대한 일반 지식이 필요하지 않은 코딩, 수학, 과학 문제 해결에 특히 강점이 있음  \n",
    "\n",
    "\n",
    "### Chain of Thought (COT)\n",
    "**Chain of Thought (COT, 사고의 연결)** 는 복잡한 문제를 해결할 때 단계별로 논리를 전개하며 중간 추론 과정을 명시적으로 표현하는 기법입니다. 이 방법을 사용하면 모델이 더 정확한 결과를 도출할 가능성이 높아집니다.  \n",
    "\n",
    "- OpenAI의 o1 모델은 Chain of Thought (CoT) 기법을 활용하여 복잡한 문제를 단계별로 추론하는 능력을 강화한 모델입니다. 이 접근 방식은 모델이 응답을 생성하기 전에 더 많은 시간을 들여 '생각'하도록 설계되어, 특히 과학, 수학, 프로그래밍 등에서 향상된 성능을 보입니다. \r\n",
    "- \r\n",
    "o1 모델은 강화 학습을 통해 CoT 방식을 학습하였으며, 이를 통해 문제를 세분화하고 각 단계에서 논리적 추론을 수행합니다. 이러한 단계별 사고 과정은 모델이 복잡한 문제를 해결하는 데 도움을 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lYFNyycCQ2p-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "btc16h6ySPFA"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "Model = \"o1-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 모델 (o1 모델 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MsoHQlVsSywU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 문자열로 표현된 행렬을 입력받아 전치 행렬을 같은 형식으로 출력하는 Python 스크립트 예제입니다. 이 스크립트는 사용자가 입력한 문자열을 파싱하여 행렬로 변환한 후, 전치 행렬을 생성하고 다시 문자열 형식으로 출력합니다.\n",
      "\n",
      "```python\n",
      "import ast\n",
      "\n",
      "def parse_matrix(matrix_str):\n",
      "    \"\"\"\n",
      "    문자열로 표현된 행렬을 파싱하여 리스트의 리스트로 변환합니다.\n",
      "    예: '[1,2],[3,4],[5,6]' -> [[1, 2], [3, 4], [5, 6]]\n",
      "    \"\"\"\n",
      "    # 문자열을 대괄호로 감싸서 전체를 리스트로 인식하게 함\n",
      "    wrapped_str = f'[{matrix_str}]'\n",
      "    try:\n",
      "        matrix = ast.literal_eval(wrapped_str)\n",
      "        # 각 행이 리스트인지 확인\n",
      "        if all(isinstance(row, list) for row in matrix):\n",
      "            return matrix\n",
      "        else:\n",
      "            raise ValueError(\"모든 행은 리스트여야 합니다.\")\n",
      "    except (SyntaxError, ValueError) as e:\n",
      "        print(\"유효한 행렬 형식이 아닙니다.\")\n",
      "        raise e\n",
      "\n",
      "def transpose_matrix(matrix):\n",
      "    \"\"\"\n",
      "    주어진 행렬의 전치 행렬을 반환합니다.\n",
      "    \"\"\"\n",
      "    # zip(*)을 사용하여 전치\n",
      "    transposed = list(map(list, zip(*matrix)))\n",
      "    return transposed\n",
      "\n",
      "def matrix_to_string(matrix):\n",
      "    \"\"\"\n",
      "    행렬을 문자열 형식으로 변환합니다.\n",
      "    예: [[1, 3, 5], [2, 4, 6]] -> '[1,3,5],[2,4,6]'\n",
      "    \"\"\"\n",
      "    row_strings = [f'[{\",\".join(map(str, row))}]' for row in matrix]\n",
      "    return \",\".join(row_strings)\n",
      "\n",
      "def main():\n",
      "    # 입력 예시\n",
      "    input_str = input(\"행렬을 입력하세요 (예: '[1,2],[3,4],[5,6]'): \")\n",
      "    \n",
      "    try:\n",
      "        matrix = parse_matrix(input_str)\n",
      "        transposed = transpose_matrix(matrix)\n",
      "        output_str = matrix_to_string(transposed)\n",
      "        print(\"전치 행렬:\", output_str)\n",
      "    except Exception as e:\n",
      "        print(\"프로그램을 종료합니다.\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "### 사용 방법\n",
      "\n",
      "1. **스크립트 실행**: 위의 코드를 Python 파일(예: `transpose_matrix.py`)로 저장한 후, 터미널이나 명령 프롬프트에서 실행합니다.\n",
      "\n",
      "    ```bash\n",
      "    python transpose_matrix.py\n",
      "    ```\n",
      "\n",
      "2. **행렬 입력**: 스크립트가 실행되면 다음과 같이 행렬을 입력하라는 메시지가 표시됩니다.\n",
      "\n",
      "    ```\n",
      "    행렬을 입력하세요 (예: '[1,2],[3,4],[5,6]'): [1,2],[3,4],[5,6]\n",
      "    ```\n",
      "\n",
      "3. **결과 확인**: 입력한 행렬의 전치 행렬이 출력됩니다.\n",
      "\n",
      "    ```\n",
      "    전치 행렬: [1,3,5],[2,4,6]\n",
      "    ```\n",
      "\n",
      "### 예제\n",
      "\n",
      "**입력:**\n",
      "\n",
      "```\n",
      "[1,2,3],[4,5,6]\n",
      "```\n",
      "\n",
      "**출력:**\n",
      "\n",
      "```\n",
      "전치 행렬: [1,4],[2,5],[3,6]\n",
      "```\n",
      "\n",
      "### 주의 사항\n",
      "\n",
      "- 입력 문자열은 각 행이 대괄호(`[]`)로 감싸져 있어야 하며, 행 사이에는 쉼표(`,`)로 구분되어야 합니다.\n",
      "- 모든 행의 열 수가 동일해야 전치가 가능합니다.\n",
      "- 숫자 이외의 값이 포함되면 오류가 발생할 수 있습니다.\n",
      "\n",
      "이 스크립트는 기본적인 행렬 전치 기능을 제공하며, 필요에 따라 확장하거나 예외 처리를 추가하여 활용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "문자열로 표현된 행렬(예: '[1,2],[3,4],[5,6]')을 입력으로 받아, \n",
    "같은 형식으로 전치 행렬을 출력하는 Python 스크립트를 작성하세요.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=Model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 모델의 비용 관리  \r\n",
    "\r\n",
    "o1 시리즈 모델에서 비용을 관리하려면 `max_completion_tokens` 매개변수를 사용하여 모델이 생성하는 총 토큰 수(추론 토큰과 응답 토큰 포함)를 제한할 수 있습니다.  \r\n",
    "\r\n",
    "이전 모델에서는 `max_tokens` 매개변수가 생성되는 토큰 수와 사용자에게 표시되는 토큰 수를 동시에 제어했으며, 이 둘은 항상 동일했습니다. 그러나 o1 시리즈에서는 내부 추론 과정에서 추가 토큰이 생성될 수 있어, 총 생성 토큰 수가 사용자에게 표시되는 토큰 수를 초과할 수 있습니다. 때문에, o1 시리즈에서는 `max_completion_tokens`를 도입하여 모델이 생성하는 총 토큰 수(추론 + 표시된 응답 토큰)를 명확하게 제어할 수 있도록 했습니다. 이를 통해 새로운 모델을 사용할 때 기존 애플리케이션이 정상적으로 작동하도록 보장속 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 요청하신 Python 애플리케이션의 디렉터리 구조와 각 파일의 전체 내용입니다.\n",
      "\n",
      "```\n",
      "my_app/\n",
      "├── main.py\n",
      "├── db.py\n",
      "├── similarity.py\n",
      "├── requirements.txt\n",
      "└── README.md\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**`main.py`**\n",
      "```python\n",
      "import db\n",
      "import similarity\n",
      "\n",
      "def main():\n",
      "    db.initialize()\n",
      "    while True:\n",
      "        question = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \").strip()\n",
      "        if question.lower() == 'exit':\n",
      "            print(\"프로그램을 종료합니다.\")\n",
      "            break\n",
      "        answer = db.get_answer(question)\n",
      "        if answer:\n",
      "            print(f\"답변: {answer}\")\n",
      "        else:\n",
      "            user_answer = input(\"답변을 찾을 수 없습니다. 답변을 입력해주세요: \").strip()\n",
      "            db.add_qa_pair(question, user_answer)\n",
      "            print(\"질문과 답변이 저장되었습니다.\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**`db.py`**\n",
      "```python\n",
      "import sqlite3\n",
      "from similarity import are_similar\n",
      "\n",
      "DB_NAME = 'qa.db'\n",
      "SIMILARITY_THRESHOLD = 0.8\n",
      "\n",
      "def initialize():\n",
      "    conn = sqlite3.connect(DB_NAME)\n",
      "    cursor = conn.cursor()\n",
      "    cursor.execute('''\n",
      "        CREATE TABLE IF NOT EXISTS qa (\n",
      "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "            question TEXT NOT NULL,\n",
      "            answer TEXT NOT NULL\n",
      "        )\n",
      "    ''')\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "\n",
      "def get_all_qa():\n",
      "    conn = sqlite3.connect(DB_NAME)\n",
      "    cursor = conn.cursor()\n",
      "    cursor.execute('SELECT question, answer FROM qa')\n",
      "    qa_pairs = cursor.fetchall()\n",
      "    conn.close()\n",
      "    return qa_pairs\n",
      "\n",
      "def get_answer(user_question):\n",
      "    qa_pairs = get_all_qa()\n",
      "    for question, answer in qa_pairs:\n",
      "        if are_similar(user_question, question) >= SIMILARITY_THRESHOLD:\n",
      "            return answer\n",
      "    return None\n",
      "\n",
      "def add_qa_pair(question, answer):\n",
      "    conn = sqlite3.connect(DB_NAME)\n",
      "    cursor = conn.cursor()\n",
      "    cursor.execute('INSERT INTO qa (question, answer) VALUES (?, ?)', (question, answer))\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**`similarity.py`**\n",
      "```python\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "\n",
      "def are_similar(text1, text2):\n",
      "    vectorizer = TfidfVectorizer().fit_transform([text1, text2])\n",
      "    vectors = vectorizer.toarray()\n",
      "    cos_sim = cosine_similarity([vectors[0]], [vectors[1]])[0][0]\n",
      "    return cos_sim\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**`requirements.txt`**\n",
      "```\n",
      "scikit-learn\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "**`README.md`**\n",
      "```markdown\n",
      "# 질문-답변 애플리케이션\n",
      "\n",
      "사용자로부터 질문을 입력받아 데이터베이스에서 유사한 답변을 조회하거나 새로운 답변을 저장하는 Python 애플리케이션입니다.\n",
      "\n",
      "## 설치 방법\n",
      "\n",
      "1. 필요한 패키지를 설치합니다.\n",
      "\n",
      "```bash\n",
      "pip install -r requirements.txt\n",
      "```\n",
      "\n",
      "2. 애플리케이션을 실행합니다.\n",
      "\n",
      "```bash\n",
      "python main.py\n",
      "```\n",
      "\n",
      "## 사용 방법\n",
      "\n",
      "- 질문을 입력하면, 데이터베이스에서 유사한 답변을 찾습니다.\n",
      "- 유사한 답변이 없으면 사용자가 답변을 입력하여 데이터베이스에 저장합니다.\n",
      "- 종료하려면 `exit`를 입력하세요.\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "이 구조는 애플리케이션의 주요 기능을 모듈화하여 관리하기 쉽도록 설계되었습니다. `main.py`는 사용자 인터페이스를 담당하고, `db.py`는 데이터베이스와의 상호작용을 처리하며, `similarity.py`는 질문 간 유사도를 계산합니다. 필요한 패키지는 `requirements.txt`에 명시되어 있으며, `README.md`는 프로젝트 개요와 사용 방법을 설명합니다.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "사용자로부터 질문을 입력받아 데이터베이스에서 해당 질문과 매핑된 답변을 조회하는 Python 애플리케이션을 만들고 싶습니다.  \n",
    "질문과 유사한 답변이 존재하면 해당 답변을 반환하고, 존재하지 않는 경우 사용자가 답변을 입력하도록 요청한 후  \n",
    "해당 질문/답변 쌍을 데이터베이스에 저장합니다.  \n",
    "\n",
    "이 애플리케이션에 필요한 디렉터리 구조를 계획한 후, 각 파일의 전체 내용을 제공하세요.  \n",
    "코드 중간에 설명을 포함하지 말고, 처음과 끝에서만 이유를 설명하세요.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=Model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_completion_tokens=5000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론 토큰을 위한 충분한 컨텍스트 윈도우 공간 확보가 필요 합니다. 문제의 복잡성에 따라 모델은 수백 개에서 수만 개의 추론 토큰을 생성할 수 있습니다.  \r\n",
    "\r\n",
    "사용된 정확한 추론 토큰 수는 채팅 완성 응답 객체(chat completion response object)의 `usage` 객체 내 `completion_tokens_details`에서 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 1368,\n",
       " 'prompt_tokens': 145,\n",
       " 'total_tokens': 1513,\n",
       " 'completion_tokens_details': {'audio_tokens': 0,\n",
       "  'reasoning_tokens': 512,\n",
       "  'accepted_prediction_tokens': 0,\n",
       "  'rejected_prediction_tokens': 0},\n",
       " 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COT (Chain of Thought)\n",
    "**Chain of Thought (CoT)** 는 **대형 언어 모델(LLM)** 이 문제를 해결할 때 논리적 사고 과정을 단계별로 명확하게 표현하도록 유도하는 프롬프트 기법입니다.\n",
    "\n",
    "일반적인 LLM의 답변 방식은 질문에 대해 즉시 응답하는 것이지만, CoT를 활용하면 모델이 중간 사고 과정을 거쳐 더 정확하고 신뢰할 수 있는 답변을 생성할 수 있습니다. \n",
    "\n",
    "##### CoT의 핵심 원리\n",
    "- 단계별 사고 과정 유도\n",
    "- 문제를 한 번에 풀도록 요청하는 것이 아니라, **\"하나씩 논리적으로 설명한 후 답변을 제시\"**하도록 유도하는 방식입니다.\n",
    "- 모델에게 \"Let's think step by step.\"(단계별로 생각해 보자) 같은 문구를 추가하면 CoT 방식을 유도할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 일반 LLM 모델 (gpt-4o)에 COT 기법 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제를 단계별로 분석해 보겠습니다.\n",
      "\n",
      "1. **현재 사과의 수**: 냉장고에 처음에 23개의 사과가 있습니다.\n",
      "   \n",
      "2. **먹은 사과의 수**: 이 중에서 20개의 사과를 먹습니다. 그러므로, 먹은 사과의 수를 처음 사과 수에서 빼야 합니다.\n",
      "   - 23 - 20 = 3\n",
      "   - 현재 냉장고에는 3개의 사과가 남아 있습니다.\n",
      "\n",
      "3. **추가한 사과의 수**: 이후, 6개의 사과를 더 삽니다. 기존의 사과 수에 추가한 수를 더해야 합니다.\n",
      "   - 3 + 6 = 9\n",
      "   - 최종적으로 냉장고에는 9개의 사과가 남아 있습니다.\n",
      "\n",
      "따라서, 사과는 최종적으로 **9개**가 남아 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 문제\n",
    "\n",
    "# question = \"자동차가 시속 60km로 2.5시간 동안 이동하면 총 몇 km를 이동하게 될까요?\"\n",
    "\n",
    "# question = \"\"\"\n",
    "# 철수는 5개의 골프공을 가지고 있다.\n",
    "# 오늘 2박스를 더 샀다. 각 박스에는 5개의 골프 공이 들어 있다.\n",
    "# 이제 철수는 몇 개의 골프 공을 가지고 있는가?\n",
    "# \"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "냉장고에 23개의 사과가 있다. 20개를 먹고 6개를 더 샀다면, 사과는 몇 개가 남아 있는가?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "    체인 오브 소트(Chain of Thought, CoT) 추론을 사용하여 단계별로 해결해 봅시다.\n",
    "\n",
    "    질문: {question}\n",
    "\n",
    "    신중하게 생각하고, 최종 답변을 제공하기 전에 자세한 단계별 설명을 작성하세요.\n",
    "    \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "              {\n",
    "                  \"role\": \"user\", \n",
    "                  \"content\": prompt\n",
    "              }\n",
    "    ],\n",
    "    max_completion_tokens=1000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동일한 질문을 추론 모델(o1) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "냉장고에 처음에 사과가 23개 있습니다.\n",
      "\n",
      "1. **사과를 20개 먹음:**\n",
      "   \\[\n",
      "   23 - 20 = 3 \\text{개}\n",
      "   \\]\n",
      "\n",
      "2. **사과를 6개 더 구매함:**\n",
      "   \\[\n",
      "   3 + 6 = 9 \\text{개}\n",
      "   \\]\n",
      "\n",
      "따라서, 사과는 **총 9개** 남아 있습니다.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=Model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": question\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
