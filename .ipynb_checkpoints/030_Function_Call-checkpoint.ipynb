{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae088d7-3725-4567-8d0e-bbc0cac194b6",
   "metadata": {},
   "source": [
    "# 함수 호출\n",
    "- 대규모 언어 모델을 외부 도구에 연결하는 방법  \n",
    "\n",
    "- API 호출에서 함수를 설명하고 모델이 하나 이상의 함수를 호출하기 위한 인수가 포함된 JSON 개체를 출력하도록 지능적으로 선택하도록 할 수 있습니다. Chat Completions API는 함수를 호출하지 않습니다. 대신 모델은 코드에서 함수를 호출하는 데 사용할 수 있는 JSON을 생성합니다.\n",
    "- \n",
    "최신 모델(gpt-4o, gpt-4-turbo 및 gpt-3.5-turbo)은 함수를 호출해야 하는 시기(입력에 따라)를 감지하고 함수를 준수하는 JSON으로 응답하도록 훈련되었습니다. 이 기능에는 잠재적인 위험도 따릅니다. 사용자를 대신하여 세상에 영향을 미치는 조치(이메일 전송, 온라인 게시, 구매 등)를 수행하기 전에 사용자 확인 흐름을 구축하는 것이 좋습니다.다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "452e849b-75b2-44b8-b020-d29fa07c6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9ecc6-b814-408b-a883-e7c5f891299b",
   "metadata": {},
   "source": [
    "# 채팅 모델로 함수를 호출하는 방법\n",
    "\n",
    "함수 호출을 위한 기본 단계는 다음과 같습니다:\n",
    "\n",
    "1. **모델 호출**: 사용자 질의와 함께 함수 집합을 정의하여 모델을 호출합니다. 함수 목록을 `tools` 파라미터에 제공합니다.\n",
    "\n",
    "\n",
    "2. **모델의 함수 호출 선택**: 모델은 하나 이상의 함수를 호출할 수 있습니다. 이 경우, 모델의 응답 내용은 사용자가 정의한 스키마에 따른 JSON 객체 문자열이 됩니다. \n",
    "\n",
    "\n",
    "3. **JSON 파싱 및 함수 호출**: 코드에서 문자열을 JSON으로 파싱하고, 제공된 인수가 있는 경우 함수를 호출합니다.\n",
    "\n",
    "\n",
    "4. **모델 재호출 및 결과 요약**: 함수 응답을 새로운 메시지로 추가하여 모델을 다시 호출합니다. 모델이 결과를 사용자에게 요약하여 전달합니다.\n",
    "\n",
    "이 단계들은 사용자 질의에 따라 적절한 함수를 선택하고, 해당 함수의 응답을 처리하여 최종 결과를 사용자에게 제공하는 과정을 포함합니다. 이를 통해 사용자는 더 나은 응답을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e06c229b-b633-456e-9ae1-c62ebe6c79b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f7d491a-2cf4-4221-baca-9b8a1492bd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도구 호출 정보 = \n",
      "[ChatCompletionMessageToolCall(id='call_WkbSdRP4jOeNhF8HKYpg54d3', function=Function(arguments='{\"location\": \"San Francisco, CA\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_RYp3zrCmVaYxcU9qC1nKBcc6', function=Function(arguments='{\"location\": \"Tokyo, Japan\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_8TPdvJdS1YIANfxaYII9LU66', function=Function(arguments='{\"location\": \"Paris, France\"}', name='get_current_weather'), type='function')]\n",
      "\n",
      "[Function(arguments='{\"location\": \"San Francisco, CA\"}', name='get_current_weather'), Function(arguments='{\"location\": \"Tokyo, Japan\"}', name='get_current_weather'), Function(arguments='{\"location\": \"Paris, France\"}', name='get_current_weather')]\n"
     ]
    }
   ],
   "source": [
    "# 예제 더미 함수로 하드 코딩된 동일한 날씨 정보를 반환합니다.\n",
    "# 실제 환경에서는 백엔드 API 또는 외부 API가 될 수 있습니다.\n",
    "def get_current_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"지정된 위치의 현재 날씨를 가져옵니다.\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"22.2\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "# 대화 실행 함수 정의\n",
    "def run_conversation(messages):\n",
    "    # Step 1: 대화와 사용 가능한 함수들을 모델에 전달합니다.\n",
    "    messages = messages\n",
    "\n",
    "    #함수 집합 정의\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",   # 도구의 유형을 함수로 설정\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",   # 함수 이름\n",
    "                \"description\": \"지정된 위치의 현재 날씨를 가져오는 함수.\",    # 함수 설명\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",    # 파라미터의 유형을 객체로 설정\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",   # location 파라미터의 데이터 유형을 문자열로 설정\n",
    "                            \"description\": \"날씨를 알고 싶은 도시와 주 이름. 예: San Francisco, CA\",  # location 파라미터 설명\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\",   # unit 파라미터의 데이터 유형을 문자열로 설정\n",
    "                                 \"enum\": [\"celsius\", \"fahrenheit\"]},   # unit 파라미터가 가질 수 있는 값의 열거형 설정\n",
    "                    },\n",
    "                    \"required\": [\"location\"],   # location 파라미터는 필수\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto가 기본값이지만 명시적으로 설정\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls   # 응답 메시지에서 도구 호출 정보를 가져옴\n",
    "    \n",
    "    print(\"도구 호출 정보 = \")\n",
    "    print(tool_calls)\n",
    "    print()\n",
    "    print([tool_call.function for tool_call in tool_calls])\n",
    "\n",
    "    # Step 2: 모델이 함수를 호출하고자 하는지 확인합니다.\n",
    "    if tool_calls:\n",
    "        # Step 3: 함수를 호출합니다.\n",
    "        # 모델이 호출할 수 있는 함수들을 딕셔너리 형태로 정의합니다.\n",
    "        # 이 예제에서는 하나의 함수만 있지만, 여러 개의 함수가 있을 수 있습니다.\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  \n",
    "        \n",
    "        messages.append(response_message)  # 어시스턴트의 답변을 대화에 추가\n",
    "        \n",
    "        # Step 4: 각 함수 호출에 대한 정보와 함수 응답을 모델에 전달합니다.\n",
    "        for tool_call in tool_calls:   # 각 도구 호출에 대해 반복\n",
    "            \n",
    "            function_name = tool_call.function.name   # 호출할 함수 이름 가져오기\n",
    "            function_to_call = available_functions[function_name]   # 호출할 함수 가져오기\n",
    "            function_args = json.loads(tool_call.function.arguments)   # 함수 인수 파싱\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),   # location 인수 전달\n",
    "                unit=function_args.get(\"unit\"),   # unit 인수 전달\n",
    "            )\n",
    "            \n",
    "            # 함수 응답을 대화에 추가\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,   # 도구 호출 ID\n",
    "                    \"role\": \"tool\",     # 역할 설정 (도구)\n",
    "                    \"name\": function_name,   # 함수 이름\n",
    "                    \"content\": function_response,   # 함수 응답 내용\n",
    "                }\n",
    "            )  \n",
    "            \n",
    "        # 함수 응답을 모델이 볼 수 있도록 새로운 응답을 요청\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "        )  \n",
    "        return second_response\n",
    "\n",
    "# 대화 실행 및 결과 출력\n",
    "messages = [{\"role\": \"user\", \"content\": \"샌프란시스코, 도쿄, 파리의 날씨는 어떻습니까?\"}]\n",
    "response = run_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4166dc43-b95c-48b3-91bb-949fc5592701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9XKGzKocN9GdrraHOyCx6AGTo9hQH',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': '현재 샌프란시스코의 기온은 22.2도입니다.\\n도쿄의 기온은 10도이고,\\n파리의 기온은 22도입니다.\\n\\n세 도시 모두 비교적 온화한 날씨를 보이고 있지만, 도쿄는 다른 두 도시에 비해 더 쌀쌀한 날씨를 보이고 있습니다.',\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1717729781,\n",
       " 'model': 'gpt-4o-2024-05-13',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_319be4768e',\n",
       " 'usage': {'completion_tokens': 80, 'prompt_tokens': 162, 'total_tokens': 242}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6fabaad-8ed9-43c9-8bd3-31c6faa0d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 샌프란시스코의 기온은 22.2도입니다.\n",
      "도쿄의 기온은 10도이고,\n",
      "파리의 기온은 22도입니다.\n",
      "\n",
      "세 도시 모두 비교적 온화한 날씨를 보이고 있지만, 도쿄는 다른 두 도시에 비해 더 쌀쌀한 날씨를 보이고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561e47c-48f9-42e5-866b-3e93c0b45b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
