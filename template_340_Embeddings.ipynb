{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f780ca-9e08-4017-b4eb-00b7c5eebf35",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "OpenAI의 텍스트 임베딩은 텍스트 문자열의 관련성을 측정합니다. 임베딩은 일반적으로 다음 용도로 사용됩니다.\n",
    "\n",
    "- 두 텍스트 사이의 관련성을 측정하는 데 사용할 수 있는 텍스트의 숫자 표현  \n",
    "- 검색, 클러스터링, 추천, 이상 탐지 및 분류 작업에 유용\n",
    "\n",
    "    - 검색 (쿼리 문자열과의 관련성을 기준으로 결과 순위 지정)  \n",
    "    - 클러스터링 (텍스트 문자열이 유사성을 기준으로 그룹화)  \n",
    "    - 추천 (관련 문자열이 포함된 항목을 추천)  \n",
    "    - 이상 탐지 (관련성이 거의 없는 이상값이 식별되는 경우)  \n",
    "    - 다양성 측정 (유사성 분포를 분석)\n",
    "    - 분류 (텍스트 문자열이 가장 유사한 레이블로 분류)\n",
    "  \n",
    "임베딩은 부동 소수점 숫자의 벡터(목록)입니다. 두 벡터 사이의 거리는 관련성 을 측정합니다. 거리가 작을수록 관련성이 높음을 나타내고, 거리가 멀면 관련성이 낮다는 것을 나타냅니다.  \n",
    "\n",
    "<img src=https://cdn.sanity.io/images/vr8gru94/production/e016bbd4d7d57ff27e261adf1e254d2d3c609aac-2447x849.png width=600 />\n",
    "\n",
    "### 벡터 유사도:\n",
    "\n",
    "이제 두 개의 서로 다른 영화에 대한 두 개의 숫자 목록이 있다고 가정해 보겠습니다. 영화가 비슷한지 어떻게 알 수 있나요? 여기서 벡터 유사도가 측정됩니다.\n",
    "\n",
    "요약하면,\n",
    "\n",
    "- **임베딩**은 컴퓨터가 이해할 수 있는 특수 숫자 코드로 영화 등의 자세한 설명을 작성하는 것과 같습니다.\n",
    "- **벡터 유사도**는 두 영화와 같이 두 숫자 집합이 나타내는 항목이 서로 얼마나 유사한지 알 수 있습니다.\n",
    "\n",
    "\n",
    "<img src=https://cdn.sanity.io/images/vr8gru94/production/5a5ba7e0971f7b6dc4697732fa8adc59a46b6d8d-338x357.png width=200 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b2c71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479534de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5ce68fd-4374-4f99-8118-0606ca58b9cb",
   "metadata": {},
   "source": [
    "## API 사용 방법\n",
    "\n",
    "- 기본적으로 임베딩 벡터의 길이는 text-embedding-3-small의 경우 1536이고 text-embedding-3-large의 경우 3072입니다. 차원 매개변수를 전달하면 임베딩이 개념을 나타내는 속성을 잃지 않고  임베딩의 차원을 줄일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0856bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 임베딩 생성 요청\n",
    "# 응답에서 임베딩 데이터의 처음 10개 요소를 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c7f778-306e-43ab-b19b-15bf5d6c5935",
   "metadata": {},
   "source": [
    "- 여러 문장의 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31743401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model=embedding_model):\n",
    "# 코사인 유사도 계산 함수\n",
    "def cosine_similarity(vec1, vec2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 텍스트를 벡터(임베딩)로 변환하여 리스트에 저장\n",
    "# 두 개의 벡터(임베딩) 사이의 코사인 유사도를 계산하여 비교\n",
    "# 각 텍스트 출력 (인덱스와 함께 표시)\n",
    "# 코사인 유사도 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ad76f-004e-450f-8827-3897510512ea",
   "metadata": {},
   "source": [
    "## Amazon 고급 음식 리뷰를 이용한 Text Search\n",
    "\n",
    "데이터 세트에는 2012년 10월까지 Amazon 사용자가 남긴 총 568,454개의 음식 리뷰가 포함되어 있습니다. 이 중 가장 최근 리뷰 1,000개로 구성된 이 데이터 세트의 하위 세트를 사용합니다. 리뷰는 영어로 작성되며 긍정적이거나 부정적입니다. 각 리뷰에는 ProductId, UserId, 점수, 리뷰 제목(요약) 및 리뷰 본문(텍스트)이 있습니다.\n",
    "\n",
    "리뷰 요약과 리뷰 텍스트를 하나의 결합 텍스트로 결합합니다. 모델은 이 결합된 텍스트를 인코딩하고 단일 벡터 임베딩을 출력합니다. \n",
    "\n",
    "이 예제에서는 api 비용 절약을 위해 1000 개의 한국어 번역 버전을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 원본 데이터셋: \"data/fine_food_reviews_1k.csv\"\n",
    "# 한국어로 번역된 데이터셋: \"data/fine_food_reviews_1k_fully_translated_korean.csv\"\n",
    "# CSV 파일을 데이터프레임으로 읽기 (첫 번째 열을 인덱스로 사용)\n",
    "# 필요한 컬럼만 선택하여 데이터 정리\n",
    "# 결측값(NaN) 제거\n",
    "# \"Summary\"와 \"Text\"를 결합하여 \"combined\" 컬럼 생성\n",
    "# \"Time\" 컬럼 제거 (분석에 필요하지 않다고 가정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c673818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316966dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"cl100k_base\"는 OpenAI의 최신 임베딩 모델(`text-embedding-3-small`, `text-embedding-3-large` 등)과 호환되는 인코딩 방식\n",
    "# 지정된 인코딩 방식을 가져와서 사용\n",
    "# 텍스트를 토큰화하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26bd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-embedding-3-small 모델의 최대 입력 토큰 수는 8191이므로, 안전하게 8000으로 설정\n",
    "# 각 리뷰의 토큰 개수 계산\n",
    "# 최대 토큰 수를 초과하는 리뷰 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수분(5-6분) 정도 소요됩니다. \n",
    "# # \"combined\" 컬럼(리뷰 제목 + 본문)에 대해 임베딩을 생성하여 \"embedding\" 컬럼에 저장\n",
    "# df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, model=embedding_model))\n",
    "# # 임베딩이 포함된 데이터프레임을 CSV 파일로 저장\n",
    "# df.to_csv(\"output/fine_food_reviews_with_embeddings_1k.csv\")\n",
    "# 한번 저장해 놓은 임베딩을 시간과 비용 절약을 위해 재사용.\n",
    "# 저장된 임베딩을 리스트 형태로 변환하여 다시 활용 가능하도록 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854399e-2d7f-4ac3-8746-6d87aed3af4a",
   "metadata": {},
   "source": [
    "- 가장 관련성이 높은 문서를 검색하기 위해 쿼리의 임베딩 벡터와 각 문서 간의 코사인 유사성을 사용하고 가장 높은 점수를 받은 문서를 반환합니다.\n",
    "- 'delicious beans'라는 제품 설명과 유사한 상위 3개의 리뷰를 검색하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0272b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 제품 설명에 대한 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 각 임베딩과 제품 설명 임베딩 간의 유사도 계산\n",
    "# 유사도를 기준으로 내림차순 정렬하고 상위 n개의 리뷰 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016acfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
